{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1883d-da11-4503-8c0f-1bc4c3610fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca7b74-2118-4ffa-81cf-0087951f8b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import draw_segmentation_masks\n",
    "import cv2\n",
    "from torchvision.transforms import functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import pandas as pd\n",
    "import MyUtils.Dataset\n",
    "from MyUtils.visualize import visualize_masks\n",
    "import albumentations as A\n",
    "from torch.utils.data import DataLoader\n",
    "from MyUtils import transforms, utils, engine, train as transforms, utils, engine, train\n",
    "from MyUtils.utils import collate_fn\n",
    "from MyUtils.engine import train_one_epoch, evaluate\n",
    "from MyUtils.plot_statistic import plot_stats\n",
    "\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn_v2, maskrcnn_resnet50_fpn, MaskRCNN\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_V2_Weights, MaskRCNN_ResNet50_FPN_Weights\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867e543-59a1-4ad1-bbab-a44040938fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "path = 'C:/Users/User/Petr/Net_4/Dataset/'\n",
    "visualise_path = 'C:/Users/User/Petr/Net_4/Visualize/'\n",
    "\n",
    "obj_colors = {\n",
    "    'Country road': (255, 136, 0),\n",
    "    'Asphalt road': (0, 0, 0),\n",
    "    'Water': (0, 0, 255)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "#explore = sns.barplot(x=list(dataset_stats.keys()), y=list(dataset_stats.values()))\n",
    "#explore.bar_label(explore.containers[0], fontsize=10)\n",
    "#explore.set_title('Pillars with different number of visible corners')\n",
    "#explore.set_ylabel('Number of Pillars')\n",
    "#plt.show()\n",
    "\n",
    "classes = list(set([mask.split('-')[-2] for mask in os.listdir(path + 'masks/') if mask.endswith('.npy')]))\n",
    "\n",
    "classes.sort()\n",
    "\n",
    "class_index = {cls: index for index, cls in enumerate(classes)}\n",
    "\n",
    "inv_classes = {v: k for k, v in class_index.items()}\n",
    "\n",
    "\n",
    "weights = MaskRCNN_ResNet50_FPN_Weights.DEFAULT\n",
    "weights_v2 = MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "\n",
    "print(f'Dataset classes is {classes}')\n",
    "print(f'Class index is {class_index}')\n",
    "print(f'Class index inverted is {inv_classes}')\n",
    "\n",
    "dataset_stats = defaultdict(int)\n",
    "\n",
    "for mask in os.listdir(path + 'masks/'):\n",
    "    if mask.endswith('.npy'):\n",
    "        dataset_stats[mask.split('-')[-2]] += 1\n",
    "\n",
    "df = pd.DataFrame(data=dataset_stats.items(), columns=['Classes', 'Counts'])\n",
    "\n",
    "sns.barplot(data=df, x='Classes', y='Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7731f65b-e7b1-456e-a216-2ce97752db98",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    #A.RandomBrightnessContrast(p=0.5),\n",
    "    A.RandomSizedBBoxSafeCrop(height=3000, width=3000, erosion_rate=0.0, interpolation=1, always_apply=False, p=0.5),\n",
    "   #A.ToSepia(always_apply=False, p=0.5),\n",
    "    A.RGBShift(r_shift_limit=(-20, 20), g_shift_limit=(-20, 20), b_shift_limit=(-20, 20), always_apply=False, p=0.5),\n",
    "    A.RandomGravel(gravel_roi=(0.1, 0.1, 0.9, 0.9), number_of_patches=2, always_apply=False, p=0.5),\n",
    "    A.RandomShadow(shadow_roi=(0, 0, 1, 1), always_apply=False, p=0.5),\n",
    "    #A.Solarize(threshold=(200, 200), always_apply=False, p=0.5),\n",
    "    A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.3, brightness_coeff=2.5, always_apply=False, p=1.0)\n",
    "    #A.CropNonEmptyMaskIfExists(height=3000, width=3000, ignore_values=None, ignore_channels=None, always_apply=False, p=0.5),\n",
    "    ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9f9e5-8fc3-44b1-b210-1e494bb824d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_initial = MyUtils.Dataset.RoadsDataset(root=path, class_index=class_index, transform=transform)\n",
    "dataset_test_initial = MyUtils.Dataset.RoadsDataset(root=path, class_index=class_index, transform=None)\n",
    "\n",
    "print(len(dataset_train_initial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cc20f3-ce82-4388-b7ee-87554863822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = dataset_train_initial[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89652f7b-6e28-470e-817f-1160d047d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_masks(image, target, inv_classes, obj_colors=obj_colors, show=True, alpha=0.5)\n",
    "#visualize_masks(image, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79841f-2c76-4a41-8fa3-57ac1aede546",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_model(weights_path=None):\n",
    "    model = maskrcnn_resnet50_fpn(weights=weights)\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features_box = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "\n",
    "# Get the numbner of output channels for the Mask Predictor\n",
    "    dim_reduced = model.roi_heads.mask_predictor.conv5_mask.out_channels\n",
    "\n",
    "# Replace the box predictor\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_features_box, num_classes=len(classes))\n",
    "\n",
    "# Replace the mask predictor\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_channels=in_features_mask, dim_reduced=dim_reduced, num_classes=len(classes))\n",
    "\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)   \n",
    "\n",
    "# Set the model's device and data type\n",
    "    #model.to(device=device)\n",
    "\n",
    "# Add attributes to store the device and model name for later reference\n",
    "    #model.device = device\n",
    "    model.name = 'maskrcnn_resnet50_fpn_v2'\n",
    "    return model\n",
    "\n",
    "def get_mask_model_v2(weights_path=None):\n",
    "    model = maskrcnn_resnet50_fpn_v2(weights=weights_v2)\n",
    "    # Get the number of input features for the classifier\n",
    "    in_features_box = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "\n",
    "# Get the numbner of output channels for the Mask Predictor\n",
    "    dim_reduced = model.roi_heads.mask_predictor.conv5_mask.out_channels\n",
    "\n",
    "# Replace the box predictor\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_features_box, num_classes=len(classes))\n",
    "\n",
    "# Replace the mask predictor\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_channels=in_features_mask, dim_reduced=dim_reduced, num_classes=len(classes))\n",
    "\n",
    "    if weights_path:\n",
    "        state_dict = torch.load(weights_path)\n",
    "        model.load_state_dict(state_dict)   \n",
    "\n",
    "# Set the model's device and data type\n",
    "    #model.to(device=device)\n",
    "\n",
    "# Add attributes to store the device and model name for later reference\n",
    "    #model.device = device\n",
    "    model.name = 'maskrcnn_resnet50_fpn_v2'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e689077d-66db-4ff1-862f-610237fcaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/User/Petr/Net_4/save_model'\n",
    "log_path = 'C:/Users/User/Petr/Net_4/Metric_log'\n",
    "\n",
    "indices = torch.randperm(len(dataset_train_initial)).tolist()\n",
    "thirty_pc = int(len(dataset_train_initial) * 0.10)\n",
    "dataset_train = torch.utils.data.Subset(dataset_train_initial, indices[:-thirty_pc])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test_initial, indices[-thirty_pc:])\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=1, shuffle=True, collate_fn=collate_fn)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu') #torch.device('cuda') if torch.cuda.is_available() else \n",
    "\n",
    "model = get_mask_model_v2(weights_path=f'{save_path}/weights_200.pth') #weights_path=f'{save_path}/weights_50.pth'\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "    #params1 = [p for p in model.roi_heads.keypoint_head.parameters() if p.requires_grad]\n",
    "    \n",
    "optimizer = torch.optim.SGD(params, lr=1.2e-7, momentum=0.90)#, weight_decay=0.0001\n",
    "    \n",
    "    #optimizer = torch.optim.SGD([{'params': params1},\n",
    "    #                             {'params': model.roi_heads.keypoint_predictor.parameters(), 'lr': .001},], lr=0.001, momentum=0.90)#, weight_decay=0.0001\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
    "num_epochs = 301\n",
    "\n",
    "bbox_stats = []\n",
    "masks_stats=[]\n",
    "\n",
    "loss_bb = []\n",
    "loss_masks = []\n",
    "loss = []\n",
    "\n",
    "start_from = 201\n",
    "\n",
    "\n",
    "for epoch in range(start_from, num_epochs):\n",
    "    logger = train_one_epoch(model, optimizer, data_loader_train, device, epoch, print_freq=int(len(dataset_train) / 10))\n",
    "    lr_scheduler.step()\n",
    "    evaluator = evaluate(model, data_loader_test, device)\n",
    "\n",
    "    bbox_stats.append(evaluator.coco_eval['bbox'].stats[:6])\n",
    "    masks_stats.append(evaluator.coco_eval['segm'].stats[:6])\n",
    "\n",
    "    loss_masks.append(logger.meters['loss_mask'].global_avg)\n",
    "    loss_bb.append(logger.meters['loss_box_reg'].global_avg)\n",
    "    loss.append(logger.meters['loss'].global_avg)\n",
    "        \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'{save_path}/weights_{epoch+1}.pth')\n",
    "        plot_stats(epoch - start_from + 1, bbox_stats, loss_bb, loss, masks_stats=masks_stats, loss_masks=loss_masks, num=epoch+1, log_path=log_path)#, num=num\n",
    "            \n",
    "plot_stats(num_epochs - start_from, bbox_stats, loss_bb, loss, masks_stats=masks_stats, loss_masks=loss_masks, num=epoch+1, show=True, log_path=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f136b-fbb4-4598-a4b3-ae38caf419d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'{save_path}/weights_50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f045d5d-769e-4d5c-a655-cfb8fb235a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'C:/Users/User/Petr/Net_4/test_model/images/'\n",
    "out_path = 'C:/Users/User/Petr/Net_4/test_model/pred/'\n",
    "\n",
    "save_path = 'C:/Users/User/Petr/Net_4/save_model'\n",
    "model = get_mask_model_v2(weights_path=f'{save_path}/weights_70.pth')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model.to(device)\n",
    "threshold = 0.5\n",
    "\n",
    "\n",
    "for image in tqdm(os.listdir(test_path)):\n",
    "    img = cv2.imdecode(np.fromfile(os.path.join(test_path, image), dtype=np.uint8), cv2.IMREAD_UNCHANGED) #cv2.imread(os.path.join(test_path, image))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img_orig = cv2.imdecode(np.fromfile(os.path.join(test_path, image), dtype=np.uint8), cv2.IMREAD_UNCHANGED)\n",
    "    img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img = F.to_tensor(img)\n",
    "    type(img)\n",
    "    img = img.to(device)\n",
    "    with torch.no_grad():\n",
    "        #model_test.to(device)\n",
    "        model.eval()\n",
    "        out = model([img,])\n",
    "        out = out[0]\n",
    "    #img = (img[0].permute(1,2,0).detach().cpu().numpy() * 255).astype(np.uint8)\n",
    "\n",
    "    scores_valid = out['scores'] > threshold\n",
    "\n",
    "    target = {}\n",
    "    target['masks'] = out['masks'][scores_valid]\n",
    "    target['boxes'] = out['boxes'][scores_valid]\n",
    "    target['labels'] = out['labels'][scores_valid]\n",
    "\n",
    "    visualize_masks(img.detach().cpu(), target=target, inv_classes=inv_classes, obj_colors=obj_colors, alpha=0.5, save_path=out_path + image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ce6f13-1ce3-44c6-b6c1-802e8f83e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_mask_model()\n",
    "model.eval()\n",
    "pred = model([image.to(device)])\n",
    "output = pred[0]\n",
    "\n",
    "visualize_masks(image.detach().cpu(), output, inv_classes, obj_colors=obj_colors, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae342514-e27d-499d-80c9-bac7f9c45418",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2 = get_mask_model_v2()\n",
    "model_v2.eval()\n",
    "pred_v2 = model_v2([image.to(device)])\n",
    "output_v2 = pred_v2[0]\n",
    "\n",
    "visualize_masks(image.detach().cpu(), output_v2, inv_classes, obj_colors=obj_colors, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b555bf-a44b-4166-8c12-f47afb587293",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "loss_2 = [1]\n",
    "\n",
    "windows = 1 + int(bool(loss)) + int(bool(loss_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355e2cf-fb0c-442f-bfc8-ce47bdb584fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a722067-1918-47c6-af8f-d8b2126abb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
